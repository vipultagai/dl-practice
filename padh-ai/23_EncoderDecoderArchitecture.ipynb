{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "23_EncoderDecoderArchitecture.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satyajitghana/PadhAI-Course/blob/master/23_EncoderDecoderArchitecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOI4rlrgxPI-",
        "colab_type": "text"
      },
      "source": [
        "## Outline\n",
        "\n",
        "\n",
        "1. Data set and task\n",
        "2. Data processing XML files\n",
        "3. Why we need encoder decoder architecture\n",
        "4. Basic GRU based encoder decoder\n",
        "5. Adding attention\n",
        "6. Evaluation\n",
        "7. Exercises"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GqTjeV47m4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Instantiates the device to be used as GPU/CPU based on availability\n",
        "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Visualization tools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style=\"ticks\", context=\"talk\")\n",
        "plt.style.use(\"dark_background\")\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpuvHS0mxwCd",
        "colab_type": "text"
      },
      "source": [
        "## Data Management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYrAa5laSptM",
        "colab_type": "text"
      },
      "source": [
        "### Alphabets Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a04ZKx7Sh-J",
        "colab_type": "code",
        "outputId": "591376da-5e34-4673-dec3-a3e01882539d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "pad_char = '-PAD-'\n",
        "\n",
        "eng_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(eng_alphabets):\n",
        "    eng_alpha2index[alpha] = index+1\n",
        "\n",
        "print(eng_alpha2index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPSZsy1kXd9w",
        "colab_type": "code",
        "outputId": "e940fedf-7691-4a0d-a5bb-74cb2732510d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Hindi Unicode Hex Range is 2304:2432. Source: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n",
        "\n",
        "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabet_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(hindi_alphabets):\n",
        "    hindi_alpha2index[alpha] = index+1\n",
        "\n",
        "print(hindi_alpha2index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSw1SMZmx9A3",
        "colab_type": "text"
      },
      "source": [
        "### Helper functions for data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcS6ByndOxrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
        "\n",
        "# Remove all English non-letters\n",
        "def cleanEnglishVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ').upper()\n",
        "    line = non_eng_letters_regex.sub('', line)\n",
        "    return line.split()\n",
        "\n",
        "# Remove all Hindi non-letters\n",
        "def cleanHindiVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ')\n",
        "    cleaned_line = ''\n",
        "    for char in line:\n",
        "        if char in hindi_alpha2index or char == ' ':\n",
        "            cleaned_line += char\n",
        "    return cleaned_line.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob3F9Dh4PChB",
        "colab_type": "text"
      },
      "source": [
        "### Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGSeoMGg0FTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "class TransliterationDataLoader(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.eng_words, self.hindi_words = self.readXmlDataset(filename, cleanHindiVocab)\n",
        "        self.shuffle_indices = list(range(len(self.eng_words)))\n",
        "        random.shuffle(self.shuffle_indices)\n",
        "        self.shuffle_start_index = 0\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.eng_words)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.eng_words[idx], self.hindi_words[idx]\n",
        "    \n",
        "    def readXmlDataset(self, filename, lang_vocab_cleaner):\n",
        "        transliterationCorpus = ET.parse(filename).getroot()\n",
        "        lang1_words = []\n",
        "        lang2_words = []\n",
        "\n",
        "        for line in transliterationCorpus:\n",
        "            wordlist1 = cleanEnglishVocab(line[0].text)\n",
        "            wordlist2 = lang_vocab_cleaner(line[1].text)\n",
        "\n",
        "            # Skip noisy data\n",
        "            if len(wordlist1) != len(wordlist2):\n",
        "                print('Skipping: ', line[0].text, ' - ', line[1].text)\n",
        "                continue\n",
        "\n",
        "            for word in wordlist1:\n",
        "                lang1_words.append(word)\n",
        "            for word in wordlist2:\n",
        "                lang2_words.append(word)\n",
        "\n",
        "        return lang1_words, lang2_words\n",
        "    \n",
        "    def get_random_sample(self):\n",
        "        return self.__getitem__(np.random.randint(len(self.eng_words)))\n",
        "    \n",
        "    def get_batch_from_array(self, batch_size, array):\n",
        "        end = self.shuffle_start_index + batch_size\n",
        "        batch = []\n",
        "        if end >= len(self.eng_words):\n",
        "            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n",
        "            end = len(self.eng_words)\n",
        "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index : end]]\n",
        "    \n",
        "    def get_batch(self, batch_size, postprocess = True):\n",
        "        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
        "        hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n",
        "        self.shuffle_start_index += batch_size + 1\n",
        "        \n",
        "        # Reshuffle if 1 epoch is complete\n",
        "        if self.shuffle_start_index >= len(self.eng_words):\n",
        "            random.shuffle(self.shuffle_indices)\n",
        "            self.shuffle_start_index = 0\n",
        "            \n",
        "        return eng_batch, hindi_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FCCi-SerZS-",
        "colab_type": "code",
        "outputId": "1a8da676-c100-4c75-df3d-0d6d33d89639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        }
      },
      "source": [
        "train_data = TransliterationDataLoader('NEWS2012-Training-EnHi-13937.xml')\n",
        "test_data = TransliterationDataLoader('NEWS2012-Ref-EnHi-1000.xml')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping:  BARHARWA JUNCTION  -  बरहरवा\n",
            "Skipping:  STATE BNK TR  -  स्टेट बैंक ऑफ त्रावणकोर\n",
            "Skipping:  SOUTH ARLINGTON CHURCH OF CHRIST  -  साउथ अर्लिंग्टन\n",
            "Skipping:  KING EDWARD VII  -  किंग एडवर्ड\n",
            "Skipping:  DIBANG VALLEY  -  दिबंगवैली\n",
            "Skipping:  ORDER OF VASA  -  ऑडर ऑफ़ द वासा\n",
            "Skipping:  AZAMNAGAR ROAD  -  आज़मनगर\n",
            "Skipping:  CAPE TOWN  -  केपटाउन\n",
            "Skipping:  NEW ZEALAND  -  न्यूज़ीलैंड\n",
            "Skipping:  SEA OF THE HEBRIDES  -  सी ऑफ हरब्रिड्‍स\n",
            "Skipping:  RAMCOIND  -  राम्को इंड\n",
            "Skipping:  KELVINGROVE ART GALLERY AND MUSEUM  -  केल्व‍िनग्रोव आर्ट एण्ड म्युज़ियम\n",
            "Skipping:  AUSTRALIAN NATIONAL UNIVERSITY  -  ऑस्ट्रेलियननेशनल यूनिवर्सिटी\n",
            "Skipping:  JAHAN AARA  -  जहाँआरा\n",
            "Skipping:  NAVABHARAT FERRO ALLOYS  -  नव भारत फ़ैरो अलॉय\n",
            "Skipping:  RAMA LINGESHWARA  -  रामालिंगेश्वर\n",
            "Skipping:  FAKHRUN NISA  -  फखरुन्निसा\n",
            "Skipping:  REDIFF.COM INDIA LIMITED  -  रेडिफ़ डॉट कॉम इंडिया लिमिटेड\n",
            "Skipping:  OMKARNATH THAKUR  -  ओंकार नाथ ठाकुर\n",
            "Skipping:  OPENTV  -  ओपन टीवी\n",
            "Skipping:  ENVOY COMMUNICATIONS GROUP  -  एन्वॉय कम्युनिकेशंस\n",
            "Skipping:  WAR OF THE HOLY LEAGUE  -  वार ऑफ होली लीग\n",
            "Skipping:  VAPARAISO CHURCH OF CHRIST  -  व्हापरासिओ\n",
            "Skipping:  PARIS CHARLES DE GAULLE  -  पेरिस रॉसे चार्ल्स डे ग्यूले\n",
            "Skipping:  PARKWAY APOSTOLIC  -  पार्क वे अपोस्टोलिक\n",
            "Skipping:  MAUNA LOA  -  मौनालोआ\n",
            "Skipping:  MASS MUTUAL LIFE  -  मास म्युच्युअल लाइफ़ इंश्योरेंस\n",
            "Skipping:  STATS CHIPPAC  -  स्टेट्सचिपपैक\n",
            "Skipping:  NEWFOUNDLAND  -  न्यू फाउंडलैंड\n",
            "Skipping:  LONDONHEATHROW  -  लंदन हीथ्रो\n",
            "Skipping:  RETALIX  -  रेटालिक्स लि.\n",
            "Skipping:  SRISAILAM  -  श्री शैलम\n",
            "Skipping:  KARA-KUM  -  काराकुम\n",
            "Skipping:  WIND RIVER  -  विंडरिवर\n",
            "Skipping:  NETAJI SUBHASH CHANDRA BOSE  -  नेताजी सुभाषचंद्र बोस\n",
            "Skipping:  ROCKBROOK UNITED  -  रॉकब्रुक यूनाइटेड मेथोडिस्ट\n",
            "Skipping:  WALTER SCOTT  -  वॉल्टरस्कॉट\n",
            "Skipping:  COLOURPLUS FASHIONS  -  कलर प्लस फ़ैशन्स\n",
            "Skipping:  BAL KRISHNA  -  बालकृष्णा\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l-iaCVdx5Ez",
        "colab_type": "text"
      },
      "source": [
        "### Basic Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjY06ghEx76b",
        "colab_type": "code",
        "outputId": "7f00804e-7cf1-42df-9501-cf32ca80e732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "print(\"Train Set Size:\\t\", len(train_data))\n",
        "print(\"Test Set Size:\\t\", len(test_data))\n",
        "\n",
        "print('\\nSample data from train-set:')\n",
        "for i in range(10):\n",
        "    eng, hindi = train_data.get_random_sample()\n",
        "    print(eng + ' - ' + hindi)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set Size:\t 20543\n",
            "Test Set Size:\t 1000\n",
            "\n",
            "Sample data from train-set:\n",
            "REET - रीत\n",
            "GIJARE - गिजरे\n",
            "DAKU - डाकू\n",
            "BANKURA - बांकुरा\n",
            "ALDAN - एल्डन\n",
            "CAVOUR - कैवर\n",
            "SICILIA - सिसिलिया\n",
            "QABEEL - क़बील\n",
            "KAVISHWAR - कवीश्वर\n",
            "FLETA - फ्लेता\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpDP1_KYZIkv",
        "colab_type": "text"
      },
      "source": [
        "### Encoding the words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE3at5C7Sy5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_rep(word, letter2index, device = 'cpu'):\n",
        "    rep = torch.zeros(len(word)+1, 1, len(letter2index)).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        rep[letter_index][0][pos] = 1\n",
        "    pad_pos = letter2index[pad_char]\n",
        "    rep[letter_index+1][0][pad_pos] = 1\n",
        "    return rep\n",
        "\n",
        "def gt_rep(word, letter2index, device = 'cpu'):\n",
        "    gt_rep = torch.zeros([len(word)+1, 1], dtype=torch.long).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        gt_rep[letter_index][0] = pos\n",
        "    gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
        "    return gt_rep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yE3jToOrfzP",
        "colab_type": "code",
        "outputId": "bf1a4d46-d854-469d-fe44-0041d125929d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "eng, hindi = train_data.get_random_sample()\n",
        "eng_rep = word_rep(eng, eng_alpha2index)\n",
        "print(eng, eng_rep)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BELA tensor([[[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMcDjIberhc3",
        "colab_type": "code",
        "outputId": "6b4c266f-b169-4486-ebaf-cc2bd2ced77a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "hindi_gt = gt_rep(hindi, hindi_alpha2index)\n",
        "print(hindi, hindi_gt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "बेला tensor([[45],\n",
            "        [72],\n",
            "        [51],\n",
            "        [63],\n",
            "        [ 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrC3tSnm4rUk",
        "colab_type": "text"
      },
      "source": [
        "## Network Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4OgdZ_DVVC5",
        "colab_type": "text"
      },
      "source": [
        "### Encoder-Decoder (using GRU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w8ffT3w4lkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_OUTPUT_CHARS = 30\n",
        "class Transliteration_EncoderDecoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "        super(Transliteration_EncoderDecoder, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder_rnn_cell = nn.GRU(output_size, hidden_size)\n",
        "        \n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "        \n",
        "        self.verbose = verbose\n",
        "        \n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "        \n",
        "        # encoder\n",
        "        out, hidden = self.encoder_rnn_cell(input)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Encoder input', input.shape)\n",
        "            print('Encoder output', out.shape)\n",
        "            print('Encoder hidden', hidden.shape)\n",
        "        \n",
        "        # decoder\n",
        "        decoder_state = hidden\n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "        outputs = []\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Decoder state', decoder_state.shape)\n",
        "            print('Decoder input', decoder_input.shape)\n",
        "        \n",
        "        for i in range(max_output_chars):\n",
        "            \n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder intermediate output', out.shape)\n",
        "            \n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder output', out.shape)\n",
        "                self.verbose = False\n",
        "            \n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.FloatTensor(out.shape).to(device)\n",
        "            one_hot.zero_()\n",
        "            one_hot.scatter_(2, max_idx, 1)\n",
        "            \n",
        "            decoder_input = one_hot.detach()\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mFCMG2mAnGy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def infer(net, word,max_output_chars, device='cpu'):\n",
        "    net.eval().to(device)\n",
        "    word_ohe = word_rep(word, eng_alpha2index)\n",
        "    output = net(word_ohe, max_output_chars)\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cra9toTiOoPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4zaJq2pOrM8",
        "colab_type": "code",
        "outputId": "5b5ab3cf-70c5-420b-ae39-6099ad76e1ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "out = infer(net, 'INDIA', 30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder input torch.Size([6, 1, 27])\n",
            "Encoder output torch.Size([6, 1, 256])\n",
            "Encoder hidden torch.Size([1, 1, 256])\n",
            "Decoder state torch.Size([1, 1, 256])\n",
            "Decoder input torch.Size([1, 1, 129])\n",
            "Decoder intermediate output torch.Size([1, 1, 256])\n",
            "Decoder output torch.Size([1, 1, 129])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_pdzBmQOsjO",
        "colab_type": "code",
        "outputId": "cd4272c5-4f5a-4144-f53b-7499ef9e3d89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        }
      },
      "source": [
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "torch.Size([1, 129]) ॼ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n",
            "torch.Size([1, 129]) थ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEg49N9e7oTY",
        "colab_type": "text"
      },
      "source": [
        "### Encoder-Decoder with Attention \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z-1QDAz8F_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transliteration_EncoderDecoder_Attention(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "        super(Transliteration_EncoderDecoder_Attention, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder_rnn_cell = nn.GRU(hidden_size*2, hidden_size)\n",
        "        \n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "        \n",
        "        self.U = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.W = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size, 1)\n",
        "        self.out2hidden = nn.Linear(self.output_size, self.hidden_size)   \n",
        "        \n",
        "        self.verbose = verbose\n",
        "        \n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "        \n",
        "        # encoder\n",
        "        encoder_outputs, hidden = self.encoder_rnn_cell(input)\n",
        "        encoder_outputs = encoder_outputs.view(-1, self.hidden_size)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Encoder output', encoder_outputs.shape)\n",
        "        \n",
        "        # decoder\n",
        "        decoder_state = hidden\n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "        \n",
        "        outputs = []\n",
        "        U = self.U(encoder_outputs)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Decoder state', decoder_state.shape)\n",
        "            print('Decoder intermediate input', decoder_input.shape)\n",
        "            print('U * Encoder output', U.shape)\n",
        "        \n",
        "        for i in range(max_output_chars):\n",
        "            \n",
        "            W = self.W(decoder_state.view(1, -1).repeat(encoder_outputs.shape[0], 1))\n",
        "            V = self.attn(torch.tanh(U + W))\n",
        "            attn_weights = F.softmax(V.view(1, -1), dim = 1) \n",
        "            \n",
        "            if self.verbose:\n",
        "                print('W * Decoder state', W.shape)\n",
        "                print('V', V.shape)\n",
        "                print('Attn', attn_weights.shape)\n",
        "            \n",
        "            attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "            \n",
        "            embedding = self.out2hidden(decoder_input)\n",
        "            decoder_input = torch.cat((embedding[0], attn_applied[0]), 1).unsqueeze(0)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Attn LC', attn_applied.shape)\n",
        "                print('Decoder input', decoder_input.shape)\n",
        "                \n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder intermediate output', out.shape)\n",
        "                \n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder output', out.shape)\n",
        "                self.verbose = False\n",
        "            \n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.zeros(out.shape, device=device)\n",
        "            one_hot.scatter_(2, max_idx, 1) \n",
        "            \n",
        "            decoder_input = one_hot.detach()\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMD3zjdJO0Oj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net_attn = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoiQwbntO5UH",
        "colab_type": "code",
        "outputId": "54962ce3-31bd-4366-b88f-e45b561557d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "out = infer(net_attn, 'INDIA', 30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output torch.Size([6, 256])\n",
            "Decoder state torch.Size([1, 1, 256])\n",
            "Decoder intermediate input torch.Size([1, 1, 129])\n",
            "U * Encoder output torch.Size([6, 256])\n",
            "W * Decoder state torch.Size([6, 256])\n",
            "V torch.Size([6, 1])\n",
            "Attn torch.Size([1, 6])\n",
            "Attn LC torch.Size([1, 1, 256])\n",
            "Decoder input torch.Size([1, 1, 512])\n",
            "Decoder intermediate output torch.Size([1, 1, 256])\n",
            "Decoder output torch.Size([1, 1, 129])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9WSPgzlO6k8",
        "colab_type": "code",
        "outputId": "e63a0a54-5567-4331-9242-cdc6cfa1ef16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        }
      },
      "source": [
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "torch.Size([1, 129]) प\n",
            "torch.Size([1, 129]) प\n",
            "torch.Size([1, 129]) प\n",
            "torch.Size([1, 129]) २\n",
            "torch.Size([1, 129]) प\n",
            "torch.Size([1, 129]) प\n",
            "torch.Size([1, 129]) २\n",
            "torch.Size([1, 129]) प\n",
            "torch.Size([1, 129]) प\n",
            "torch.Size([1, 129]) २\n",
            "torch.Size([1, 129]) प\n",
            "torch.Size([1, 129]) प\n",
            "torch.Size([1, 129]) २\n",
            "torch.Size([1, 129]) प\n",
            "torch.Size([1, 129]) प\n",
            "torch.Size([1, 129]) २\n",
            "torch.Size([1, 129]) प\n",
            "torch.Size([1, 129]) प\n",
            "torch.Size([1, 129]) २\n",
            "torch.Size([1, 129]) प\n",
            "torch.Size([1, 129]) प\n",
            "torch.Size([1, 129]) २\n",
            "torch.Size([1, 129]) प\n",
            "torch.Size([1, 129]) प\n",
            "torch.Size([1, 129]) २\n",
            "torch.Size([1, 129]) प\n",
            "torch.Size([1, 129]) प\n",
            "torch.Size([1, 129]) २\n",
            "torch.Size([1, 129]) प\n",
            "torch.Size([1, 129]) प\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyE2tSnmAW6x",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H893cimDtTUE",
        "colab_type": "text"
      },
      "source": [
        "### Core Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m804jsH7AXSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
        "    \n",
        "    net.train().to(device)\n",
        "    opt.zero_grad()\n",
        "    eng_batch, hindi_batch = train_data.get_batch(batch_size)\n",
        "    \n",
        "    total_loss = 0\n",
        "    for i in range(batch_size):\n",
        "        \n",
        "        input = word_rep(eng_batch[i], eng_alpha2index, device)\n",
        "        gt = gt_rep(hindi_batch[i], hindi_alpha2index, device)\n",
        "        outputs = net(input, gt.shape[0], device, ground_truth = gt if teacher_force else None)\n",
        "        \n",
        "        for index, output in enumerate(outputs):\n",
        "            loss = criterion(output, gt[index]) / batch_size\n",
        "            loss.backward(retain_graph = True)\n",
        "            total_loss += loss\n",
        "        \n",
        "    opt.step()\n",
        "    return total_loss/batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-eZaBxstWz9",
        "colab_type": "text"
      },
      "source": [
        "### Training Helper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rjto129ssrpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
        "    \n",
        "    net = net.to(device)\n",
        "    criterion = nn.NLLLoss(ignore_index = -1)\n",
        "    opt = optim.Adam(net.parameters(), lr=lr)\n",
        "    teacher_force_upto = n_batches//3\n",
        "    \n",
        "    loss_arr = np.zeros(n_batches + 1)\n",
        "    \n",
        "    for i in range(n_batches):\n",
        "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto ))/(i + 1)\n",
        "        \n",
        "        if i%display_freq == display_freq-1:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            print('Iteration', i, 'Loss', loss_arr[i])\n",
        "            plt.figure()\n",
        "            plt.plot(loss_arr[1:i], '-*')\n",
        "            plt.xlabel('Iteration')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "            print('\\n\\n')\n",
        "            \n",
        "    torch.save(net, 'model.pt')\n",
        "    return loss_arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZY6RvqLtdX8",
        "colab_type": "text"
      },
      "source": [
        "### Training without Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oQ3ZIWvtjfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6LjVKQfoVMU",
        "colab_type": "code",
        "outputId": "57e04e3b-e080-4e3b-ebaa-53d75334042b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        }
      },
      "source": [
        "train_setup(net, lr=0.001, n_batches=2000, batch_size = 64, display_freq=10, device = device_gpu)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1999 Loss 0.18503771722316742\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAEcCAYAAACBPmBXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Transliteration_EncoderDecoder. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LogSoftmax. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.52984333, 0.5183779 , ..., 0.18506476, 0.18503772,\n",
              "       0.18499501])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM1Tj20omMi1",
        "colab_type": "text"
      },
      "source": [
        "### Training with Attention "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxFLBqW1Ip4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net_att = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdRpJUXNIwuv",
        "colab_type": "code",
        "outputId": "c3b3c917-35d0-402f-b51b-466307c25ae7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        }
      },
      "source": [
        "loss_history = train_setup(net_att, lr=0.001, n_batches=2000, batch_size = 64, display_freq=10, device = device_gpu)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1999 Loss 0.14035944640636444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAEcCAYAAACBPmBXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nX9Zf++GHPZ4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Transliteration_EncoderDecoder_Attention. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LogSoftmax. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05F1-FwX6YVZ",
        "colab_type": "text"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3TWC7zhAn3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(net, word, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    outputs = infer(net, word, 30, device)\n",
        "    hindi_output = ''\n",
        "    for out in outputs:\n",
        "        val, indices = out.topk(1)\n",
        "        index = indices.tolist()[0][0]\n",
        "        if index == 0:\n",
        "            break\n",
        "        hindi_char = hindi_alphabets[index+1]\n",
        "        hindi_output += hindi_char\n",
        "    print(word + ' - ' + hindi_output)\n",
        "    return hindi_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT8bibYl7CgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_accuracy(net, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    predictions = []\n",
        "    accuracy = 0\n",
        "    for i in range(len(test_data)):\n",
        "        eng, hindi = test_data[i]\n",
        "        gt = gt_rep(hindi, hindi_alpha2index, device)\n",
        "        outputs = infer(net, eng, gt.shape[0], device)\n",
        "        correct = 0\n",
        "        for index, out in enumerate(outputs):\n",
        "            val, indices = out.topk(1)\n",
        "            hindi_pos = indices.tolist()[0]\n",
        "            if hindi_pos[0] == gt[index][0]:\n",
        "                correct += 1\n",
        "        \n",
        "        accuracy += correct/gt.shape[0]\n",
        "    accuracy /= len(test_data)\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy1bQiORAs5o",
        "colab_type": "code",
        "outputId": "4b54a63e-32db-41b4-ddd6-c6bf619776f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "accuracy = calc_accuracy(net) * 100\n",
        "accuracy_attn = calc_accuracy(net_att) * 100\n",
        "print('Accuracy w/o attention ', accuracy)\n",
        "print('Acurracy with attention', accuracy_attn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy w/o attention  62.59870213120213\n",
            "Acurracy with attention 70.2401767676769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaTb7CJOaJPW",
        "colab_type": "code",
        "outputId": "d80c8c25-a209-40a2-a84b-45974a2839a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "infer(net, 'INDIA', 30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[-17.0456, -16.3240,  -9.2048, -11.5201, -16.2652, -15.6178,  -7.3903,\n",
              "           -6.8018,  -0.0310,  -5.1477,  -9.5361, -11.5068, -11.7107, -16.1501,\n",
              "          -16.1183, -15.9656,  -4.3067,  -7.6197, -11.1749, -15.5286,  -9.3734,\n",
              "          -13.8978, -13.7479, -13.0406, -17.1676, -15.9869, -16.2356, -12.2222,\n",
              "          -12.3703, -12.7194, -12.1451, -11.4584, -16.6463, -15.3429,  -9.1071,\n",
              "          -13.4765,  -9.3754, -16.1615, -14.3392, -10.1317, -12.5123,  -5.1313,\n",
              "          -16.2417, -18.6822, -14.8439, -10.9312, -13.1008,  -6.8999,  -6.7277,\n",
              "          -16.1432, -15.8744,  -9.4327, -16.1155, -16.2678, -12.7030, -13.1323,\n",
              "          -14.4427, -13.0486,  -8.6713, -15.7563, -16.1996, -16.3623, -15.6003,\n",
              "          -16.4188, -12.5531, -14.2428, -17.3295, -15.8822, -19.8002, -15.5607,\n",
              "          -16.4421, -16.2711, -14.9427, -14.0234, -19.6163, -16.0163, -17.1887,\n",
              "          -18.0612, -18.7160, -15.9096, -16.5779, -16.1214, -15.8391, -15.8396,\n",
              "          -16.0235, -15.6170, -16.3806, -15.7709, -15.8360, -12.6180, -13.7949,\n",
              "          -16.4168, -11.8489, -14.7124, -16.1607, -15.3761, -15.9271, -15.5402,\n",
              "          -16.1739, -16.4328, -15.8040, -16.4793, -10.4061, -15.4271, -16.3581,\n",
              "          -15.8896, -16.0984, -16.1802, -15.6160, -16.5365, -15.9116, -17.0950,\n",
              "          -16.1883, -16.1851, -16.6505, -16.2984, -16.0108, -16.1332, -15.7845,\n",
              "          -16.0852, -16.0367, -15.1712, -15.9947, -15.1703, -16.2064, -16.0178,\n",
              "          -15.9097, -16.2456, -16.0184]], grad_fn=<ViewBackward>),\n",
              " tensor([[-14.5090, -16.4086,  -5.6107,  -0.0880, -16.8022, -16.5375, -13.2365,\n",
              "           -9.2251,  -6.3874,  -8.8188, -14.1554, -13.0594, -14.3376, -16.1436,\n",
              "          -16.4678, -16.0299, -10.0548, -11.9047, -15.1236, -16.1302, -11.9657,\n",
              "          -17.4886, -10.5683,  -9.7686, -11.8898, -11.6524, -16.6883,  -8.5909,\n",
              "          -10.4791, -11.2324, -12.1283, -12.8318, -11.7933, -11.8377,  -4.9954,\n",
              "          -11.5097,  -4.5077, -10.5677,  -9.6901,  -5.6061,  -8.1484,  -2.9632,\n",
              "          -16.3372, -13.8381,  -9.1669, -10.6661, -10.8401,  -7.9629,  -8.2357,\n",
              "          -14.6096, -16.4413,  -8.3124, -15.4063, -16.1495, -10.5618,  -9.3375,\n",
              "          -13.7276, -12.1923,  -8.5585, -16.1896, -16.2665, -11.8032, -15.6697,\n",
              "           -9.1440,  -6.5735,  -9.6727, -12.5463, -13.2802, -16.2545, -15.6806,\n",
              "          -10.8128, -16.1997,  -7.2906,  -7.0571, -12.2234, -16.5452, -11.4961,\n",
              "          -14.5594, -15.3299, -15.8498, -16.2025, -16.5863, -15.7325, -15.7091,\n",
              "          -15.8512, -15.8035, -16.4974, -16.1841, -16.0688, -10.7724, -11.1013,\n",
              "          -14.5915,  -9.4765,  -8.9485, -14.4057, -12.0682, -16.6913, -16.1850,\n",
              "          -16.3443, -16.5660, -15.9896, -16.5808, -12.9797, -16.5212, -16.1922,\n",
              "          -15.9487, -16.1808, -16.0580, -16.7392, -15.8916, -16.1400, -16.5884,\n",
              "          -16.0767, -16.7008, -16.5078, -16.0710, -15.9222, -16.3623, -16.1017,\n",
              "          -15.7428, -16.3856, -15.5172, -16.4511, -16.0354, -16.0668, -15.9165,\n",
              "          -16.1018, -16.2730, -16.3964]], grad_fn=<ViewBackward>),\n",
              " tensor([[-10.0902, -15.2828,  -8.5786,  -7.3496, -16.0112, -15.4452, -11.6020,\n",
              "          -10.7294,  -9.2053, -10.8524, -12.8580, -14.1650, -14.6189, -15.6713,\n",
              "          -15.1125, -15.1503, -10.4580, -13.1995, -14.5539, -15.3345, -13.6517,\n",
              "          -16.7820,  -9.9290, -10.7461,  -8.3008,  -8.7162, -15.6702,  -8.4873,\n",
              "          -10.5945,  -9.1183, -10.6113, -10.9095, -10.3387, -11.0656,  -0.2608,\n",
              "           -9.3695,  -9.0751, -10.0067, -10.1042,  -1.9423,  -4.3388,  -7.5020,\n",
              "          -15.6681,  -9.0317,  -7.6055, -12.0168, -11.1903, -12.9947,  -9.7395,\n",
              "          -12.9563, -15.9488,  -8.8951, -14.9426, -15.2578,  -6.9202,  -9.3294,\n",
              "           -9.9713,  -9.7009,  -9.5866, -15.2713, -15.1963,  -8.4683, -15.5253,\n",
              "           -9.3156,  -4.2740,  -6.2628,  -9.7241, -12.3521,  -9.5786, -15.4076,\n",
              "          -13.7422, -15.2813,  -8.7218, -10.3622, -14.8198, -15.7834, -11.1898,\n",
              "          -13.6596,  -2.9812, -14.8950, -15.5307, -15.5918, -15.1816, -15.3848,\n",
              "          -15.5377, -15.3702, -15.1415, -15.5761, -15.1385, -11.0637, -12.9473,\n",
              "          -11.9678,  -9.2340,  -7.0575, -11.8424, -11.0788, -15.2785, -15.1841,\n",
              "          -15.0448, -15.3969, -15.3311, -15.6180, -13.9728, -15.4330, -15.0868,\n",
              "          -15.4774, -15.2742, -15.0980, -15.5847, -15.0450, -16.0658, -15.5064,\n",
              "          -15.3597, -15.4254, -15.6482, -14.8983, -15.4043, -15.2828, -15.2984,\n",
              "          -15.0725, -15.2942, -15.0333, -15.7932, -15.3825, -14.8027, -15.0133,\n",
              "          -15.0599, -15.1366, -15.6415]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -7.1452, -15.6702, -12.6411, -10.7400, -16.9916, -16.3899, -12.3098,\n",
              "          -10.8670,  -9.2637,  -9.3365, -15.2681, -14.6401, -14.3297, -16.7509,\n",
              "          -15.6839, -16.6412, -11.6370, -13.4366, -17.0603, -16.3354, -12.9566,\n",
              "          -16.9166,  -8.9984, -11.9932, -10.9078, -12.6833, -16.2271, -10.0609,\n",
              "          -12.6076,  -8.6443, -12.0792, -10.5416, -11.5618, -13.1263,  -4.4316,\n",
              "          -11.7582, -10.4491, -10.7775, -13.3512,  -6.0958,  -9.6575,  -6.9989,\n",
              "          -16.5680, -11.2560, -10.4652, -11.3472, -12.9954,  -9.8465,  -6.1560,\n",
              "           -9.5937, -16.3812,  -6.2934, -15.8223, -16.1889,  -8.0434, -10.0201,\n",
              "          -10.8391,  -7.1587, -11.3897, -16.1345, -16.1574,  -4.9978, -16.4879,\n",
              "           -4.9424,  -0.1028,  -3.3792,  -8.9307, -10.7945, -10.3345, -16.0292,\n",
              "          -11.8413, -16.1609,  -6.5566,  -8.2656, -13.2191, -15.9852,  -9.6795,\n",
              "          -13.0351,  -3.6717, -15.8676, -16.2238, -16.0474, -16.2976, -16.5355,\n",
              "          -16.1745, -16.1589, -16.3704, -16.5331, -16.1572, -10.2636, -15.1167,\n",
              "          -14.8846,  -8.7601,  -8.4927, -13.0719, -15.2844, -16.2884, -16.2863,\n",
              "          -16.3124, -16.5786, -15.7280, -16.2857, -14.0744, -16.1880, -16.0634,\n",
              "          -16.2054, -16.3260, -16.3326, -16.3710, -15.7775, -16.9788, -16.2830,\n",
              "          -16.3416, -16.2573, -16.7975, -16.0775, -16.1995, -16.0074, -16.4528,\n",
              "          -15.9710, -16.0615, -16.1494, -16.4276, -16.0140, -15.8487, -16.0587,\n",
              "          -16.4381, -16.3937, -16.4418]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -3.8637, -16.2110, -11.4330, -12.3598, -16.7248, -16.6236,  -8.8222,\n",
              "           -5.7267,  -6.9726,  -6.0370, -12.8045, -12.7174, -15.3949, -16.6643,\n",
              "          -16.0923, -17.1715,  -8.2486, -12.4731, -15.7252, -16.7573,  -8.0637,\n",
              "          -15.2201,  -6.1161,  -9.7674, -13.2746, -14.6070, -16.4885, -10.9714,\n",
              "          -13.5993,  -6.8969, -11.4127,  -8.8841, -12.7590, -13.7133,  -8.1389,\n",
              "          -15.1553,  -8.8800, -11.0094, -14.4479,  -9.8195, -12.4867,  -6.8290,\n",
              "          -16.8503, -15.7136, -13.7143,  -9.9542, -12.5625,  -6.5888,  -0.0733,\n",
              "           -9.8964, -16.4916,  -6.5709, -16.3611, -16.6456, -10.3764,  -8.9799,\n",
              "           -9.6269,  -8.2138,  -8.1339, -16.3820, -16.2894,  -6.9983, -16.7843,\n",
              "           -4.3394,  -4.0529,  -6.3531, -11.7964, -12.5761, -15.9912, -16.3857,\n",
              "          -12.9215, -16.7178,  -8.9804, -10.3283, -15.4508, -16.2419, -11.7781,\n",
              "          -14.5878,  -9.5216, -16.2838, -16.4183, -16.6309, -16.7006, -16.8330,\n",
              "          -16.6549, -16.2932, -16.9541, -17.1293, -16.4684, -10.9664, -13.9694,\n",
              "          -16.6262,  -8.0872, -11.3243, -15.2631, -17.6631, -17.1118, -16.3099,\n",
              "          -16.7723, -17.3048, -16.0558, -16.3454, -13.4617, -16.1953, -16.1190,\n",
              "          -16.7025, -16.5130, -16.7210, -16.1962, -16.1439, -16.8443, -16.6969,\n",
              "          -16.5494, -16.4054, -16.8742, -16.4439, -16.3887, -16.5336, -16.9615,\n",
              "          -16.4026, -16.3281, -16.0673, -16.6642, -16.3920, -16.5231, -16.0796,\n",
              "          -17.0079, -16.5023, -16.7987]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -2.7518, -17.7309, -11.1614, -13.3524, -18.1828, -18.0389, -10.5604,\n",
              "           -6.7381, -11.7748,  -7.3771, -15.6984, -13.0060, -16.5217, -18.0751,\n",
              "          -17.2960, -18.2112, -10.7149, -14.5402, -16.7219, -18.4072,  -9.9293,\n",
              "          -15.3874,  -7.5168, -10.7684, -14.7691, -16.6749, -17.9150, -12.3186,\n",
              "          -15.0775,  -9.9237, -12.7389, -11.9014, -15.2934, -15.2751, -12.2827,\n",
              "          -15.4664,  -9.2237, -12.7187, -15.5828, -10.9857, -14.5398,  -7.6033,\n",
              "          -18.4268, -17.5857, -15.6667, -11.2998, -12.7762,  -6.5340,  -4.7668,\n",
              "          -10.2905, -18.1049,  -7.9023, -18.2263, -18.3948, -13.9894, -12.2019,\n",
              "          -12.1622, -11.0805,  -8.6514, -17.7022, -18.2165,  -7.0734, -18.2549,\n",
              "           -0.0846,  -6.3776,  -8.6855, -10.7301, -10.4192, -16.2407, -17.9302,\n",
              "          -11.2582, -18.0008,  -7.9630,  -8.8759, -13.0161, -18.0702,  -8.6538,\n",
              "          -12.6976, -11.0152, -18.2508, -18.0336, -18.3870, -18.0652, -18.0028,\n",
              "          -18.1382, -17.9489, -18.6421, -18.6699, -17.7865, -12.9286, -15.4458,\n",
              "          -18.0795, -10.7160, -12.4046, -16.8738, -18.8992, -18.4492, -17.8131,\n",
              "          -18.5323, -18.7813, -17.5078, -17.7980, -15.0053, -17.7685, -17.7662,\n",
              "          -18.2273, -18.0003, -18.5981, -17.5906, -17.6169, -18.2797, -18.1633,\n",
              "          -17.9154, -18.0796, -18.0435, -17.8780, -18.1557, -17.7052, -18.6516,\n",
              "          -18.0856, -17.8006, -17.6600, -18.1863, -17.4326, -18.1760, -17.4245,\n",
              "          -18.2683, -18.2092, -18.5680]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.0521, -16.8360,  -7.7299, -11.4237, -16.9784, -17.3621, -10.9062,\n",
              "           -6.9417,  -9.7114,  -7.3211, -13.9342, -12.8687, -16.7620, -17.2233,\n",
              "          -16.6753, -16.9409, -10.8797, -14.4827, -16.3234, -17.4124, -10.4955,\n",
              "          -17.3069,  -7.5190,  -9.6578, -14.7671, -16.4733, -16.8711, -12.0919,\n",
              "          -13.6356, -10.4136, -12.9893, -12.1767, -15.0188, -14.1281, -14.3706,\n",
              "          -15.5010,  -9.5660, -12.6665, -14.2010, -12.3282, -14.5299,  -8.1411,\n",
              "          -17.3373, -16.9615, -15.0005, -12.8990, -12.7044,  -8.9996,  -6.9601,\n",
              "          -11.4964, -17.1412,  -8.5588, -17.0501, -17.4104, -12.6246, -12.0315,\n",
              "          -11.5600, -12.1903,  -7.4147, -16.8189, -17.3020,  -8.7814, -17.2558,\n",
              "           -3.0943, -10.0788, -12.0646, -12.0118, -12.3275, -17.8609, -16.9725,\n",
              "          -12.5455, -17.1210, -10.3132, -11.1457, -14.6299, -16.9070, -10.7638,\n",
              "          -13.7398, -11.0412, -17.3415, -17.1747, -17.2455, -16.6820, -16.6102,\n",
              "          -17.0604, -16.8740, -18.0889, -17.7527, -17.0634, -12.8920, -14.1168,\n",
              "          -17.2285, -13.5868, -12.9382, -16.9878, -18.1315, -17.4304, -16.7090,\n",
              "          -17.9464, -17.9469, -16.8409, -17.0846, -14.4294, -16.9040, -16.8262,\n",
              "          -17.1111, -17.1062, -17.3955, -16.9159, -16.4244, -16.9759, -17.1589,\n",
              "          -17.0584, -17.1961, -17.0599, -17.1999, -17.2822, -17.0003, -17.3710,\n",
              "          -16.8310, -17.0183, -16.5225, -17.1068, -16.6756, -17.3699, -16.3783,\n",
              "          -17.3335, -17.2931, -17.3259]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.0905, -15.6986,  -8.7976, -10.6486, -16.0395, -16.2453,  -9.9041,\n",
              "           -7.4144, -11.2299,  -8.1127, -14.8681, -12.6515, -15.5236, -16.3962,\n",
              "          -15.7870, -15.6822, -10.1735, -13.7339, -14.6413, -16.1037, -10.9632,\n",
              "          -15.6078,  -6.7591, -10.2304, -12.7591, -14.8819, -15.7996, -10.8339,\n",
              "          -12.8680,  -9.7838, -12.5526, -11.8207, -12.8933, -12.9880, -13.1995,\n",
              "          -13.7726,  -9.6499, -11.1468, -13.0416, -10.3062, -13.6810,  -8.8095,\n",
              "          -16.2509, -13.8987, -12.6705, -12.5278, -12.3458, -10.5682,  -8.8231,\n",
              "          -10.2339, -15.9765,  -9.1889, -15.8830, -16.4821, -10.0757, -11.2608,\n",
              "          -10.4705, -10.9367,  -8.0663, -15.7768, -15.9552,  -6.7140, -16.3110,\n",
              "           -2.5133,  -8.9120, -10.1836, -10.1163, -10.6908, -15.1103, -16.4118,\n",
              "          -11.0399, -16.2570,  -8.5200, -10.3863, -12.1543, -15.9848,  -9.0683,\n",
              "          -12.6025,  -8.8325, -16.2543, -16.0221, -16.1592, -15.4370, -15.7081,\n",
              "          -16.1150, -15.8747, -16.6369, -16.8128, -16.1955, -11.9808, -13.6127,\n",
              "          -15.7515, -13.1241, -11.6228, -15.6456, -16.3476, -16.4047, -15.8324,\n",
              "          -16.9416, -16.5149, -15.7072, -15.8528, -13.8013, -15.8269, -15.6895,\n",
              "          -15.9792, -16.0249, -16.0587, -15.9693, -15.5150, -15.9456, -16.1051,\n",
              "          -15.9569, -16.2552, -16.2715, -16.1314, -16.1419, -15.7793, -16.3496,\n",
              "          -15.5601, -15.8943, -15.6851, -16.1801, -15.6342, -16.2215, -15.5101,\n",
              "          -16.2518, -16.2975, -16.1402]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.0224, -15.8011, -10.0868,  -9.8164, -16.1732, -16.3159, -10.5743,\n",
              "           -9.2883, -11.3995,  -9.3737, -15.3012, -13.4827, -15.3812, -16.5464,\n",
              "          -16.0043, -15.8033, -10.6560, -14.4804, -13.9814, -16.2683, -11.9459,\n",
              "          -16.4201,  -7.1110, -11.4539, -13.0245, -15.7330, -15.9919, -11.7801,\n",
              "          -13.9965, -10.5167, -14.1541, -12.9513, -12.8964, -13.9634, -12.6452,\n",
              "          -14.1895, -10.6833, -11.5774, -13.8755, -10.5306, -14.4889,  -9.9435,\n",
              "          -16.2311, -12.6204, -11.0172, -12.2877, -13.3274, -11.6532, -10.7681,\n",
              "           -9.7772, -16.1082,  -9.1006, -15.8400, -16.5469, -10.1443, -12.4434,\n",
              "          -11.3908, -11.2697,  -9.8103, -15.9095, -16.2457,  -6.8976, -16.4248,\n",
              "           -3.9837,  -9.2337,  -9.6804, -10.2506, -10.9113, -14.2510, -16.6068,\n",
              "          -11.2162, -16.3678,  -8.2433, -10.9875, -12.0083, -16.0506,  -9.8180,\n",
              "          -13.5520,  -8.3258, -16.1647, -15.9008, -16.1009, -15.4863, -15.8358,\n",
              "          -16.1413, -15.9617, -16.6876, -16.5931, -16.2651, -11.9009, -14.2340,\n",
              "          -15.8287, -13.7817, -11.8735, -15.8141, -15.9165, -16.5929, -16.1321,\n",
              "          -17.0893, -16.5159, -15.9647, -16.0820, -14.2827, -16.1031, -15.7228,\n",
              "          -16.1569, -16.1369, -16.1419, -16.3207, -15.5740, -16.1456, -16.1700,\n",
              "          -15.9423, -16.4505, -16.2869, -16.3736, -16.3493, -15.9195, -16.4478,\n",
              "          -15.6010, -16.1529, -15.6775, -16.2673, -15.8679, -16.3649, -15.7435,\n",
              "          -16.2828, -16.4647, -16.1311]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.0195, -15.4107, -11.2743,  -9.3558, -15.7495, -15.9367, -10.4761,\n",
              "          -10.1748, -11.0049,  -9.7703, -14.0887, -13.6986, -13.8748, -16.1428,\n",
              "          -15.6382, -15.3131, -10.3093, -14.6837, -13.6427, -15.8840, -12.3773,\n",
              "          -16.1138,  -7.1007, -12.9161, -11.7890, -15.3579, -15.6188, -11.6525,\n",
              "          -14.4709,  -9.8129, -14.7359, -12.9989,  -9.8557, -13.2749, -11.1293,\n",
              "          -13.6382, -11.4751,  -9.8966, -13.0236, -10.0938, -14.7876, -10.3418,\n",
              "          -15.7766, -10.3611,  -9.9443, -11.4900, -13.7332, -11.3524, -11.1153,\n",
              "           -7.5644, -15.9226,  -9.2894, -15.2954, -16.2929,  -8.9689, -11.5917,\n",
              "          -10.6657,  -9.0512, -10.5163, -15.6170, -15.9082,  -5.8629, -16.1817,\n",
              "           -4.6498,  -8.6845,  -8.1934, -10.4186, -10.9092, -12.1866, -16.3979,\n",
              "          -10.3310, -16.2434,  -7.3637, -10.8096, -11.3457, -15.7693,  -9.6254,\n",
              "          -14.1565,  -5.7613, -15.6258, -15.3691, -15.7621, -15.1008, -15.5642,\n",
              "          -15.6748, -15.7530, -16.2382, -15.9452, -15.8465, -11.2786, -14.3654,\n",
              "          -15.3015, -12.6430, -11.9670, -15.4850, -14.9361, -16.0697, -15.8562,\n",
              "          -16.5034, -16.1897, -15.6245, -15.6216, -14.1612, -15.7706, -15.4334,\n",
              "          -15.9227, -15.7304, -15.6628, -16.0805, -15.1685, -15.9558, -15.7117,\n",
              "          -15.5703, -15.9436, -15.8845, -15.9828, -16.1084, -15.5641, -16.1170,\n",
              "          -15.2828, -15.8562, -15.5338, -15.8546, -15.5727, -15.7353, -15.4625,\n",
              "          -15.9021, -16.1963, -15.6044]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.0687, -15.0294, -11.6291,  -8.7416, -15.5077, -15.6788, -10.2571,\n",
              "          -10.5665, -10.7625,  -9.7004, -12.4556, -13.5593, -12.6089, -15.7910,\n",
              "          -15.2174, -14.9467,  -9.8133, -15.0661, -12.9821, -15.4899, -11.9625,\n",
              "          -15.1938,  -6.6106, -13.9779, -10.0620, -14.1670, -15.3445, -11.1649,\n",
              "          -14.8785,  -7.8167, -14.3414, -12.6830,  -5.8731, -11.9388,  -9.4492,\n",
              "          -12.9369, -11.3244,  -7.4754, -11.4479,  -9.9941, -15.0155,  -9.5649,\n",
              "          -15.4117,  -9.1379,  -9.4080, -10.4682, -13.5367, -10.7263, -10.1341,\n",
              "           -5.5117, -15.7818, -10.2715, -14.8872, -16.2593,  -7.8818, -10.3016,\n",
              "           -9.6146,  -6.2380, -10.4936, -15.2817, -15.5837,  -4.3733, -15.9968,\n",
              "           -4.6142,  -7.4157,  -6.5488, -10.0677, -10.3774, -10.6615, -16.1977,\n",
              "           -9.2497, -16.0977,  -6.0767, -10.0869, -10.2148, -15.6712,  -8.9952,\n",
              "          -14.1861,  -3.6327, -15.2002, -15.0854, -15.4204, -14.8498, -15.4144,\n",
              "          -15.3425, -15.5627, -15.7940, -15.5139, -15.4682, -10.9456, -14.3879,\n",
              "          -14.7470, -10.7034, -12.0962, -15.1814, -14.1713, -15.6125, -15.6484,\n",
              "          -15.9983, -15.9023, -15.2606, -15.2811, -13.9140, -15.4928, -15.1272,\n",
              "          -15.7742, -15.4030, -15.3662, -15.7776, -14.9047, -15.9178, -15.2757,\n",
              "          -15.3189, -15.5280, -15.6404, -15.5791, -15.9551, -15.2581, -15.8834,\n",
              "          -15.0960, -15.5619, -15.3785, -15.5045, -15.3009, -15.1705, -15.3103,\n",
              "          -15.7270, -15.8444, -15.3214]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.1868, -15.1981, -11.6865,  -8.4872, -15.8431, -16.0226,  -9.9641,\n",
              "          -10.3615, -10.4231,  -9.4812, -11.5332, -13.5262, -12.1181, -16.0630,\n",
              "          -15.4166, -15.2352,  -9.3079, -15.3030, -12.7614, -15.6613, -11.3984,\n",
              "          -14.6746,  -5.8923, -14.5147,  -8.8615, -13.4719, -15.5264, -10.8060,\n",
              "          -15.2236,  -6.0327, -13.8470, -12.3637,  -3.2862, -11.1823,  -8.6763,\n",
              "          -12.8639, -10.9925,  -5.8710, -10.5911, -10.0792, -15.2883,  -8.8010,\n",
              "          -15.6356,  -8.6789,  -9.2808,  -9.9603, -13.5836, -10.1673,  -8.9720,\n",
              "           -4.3702, -16.0978, -10.8184, -15.0845, -16.6786,  -7.1138,  -9.4351,\n",
              "           -9.0065,  -4.4044, -10.5379, -15.4669, -15.7715,  -3.5974, -16.2505,\n",
              "           -4.7387,  -6.9416,  -5.9125,  -9.8557,  -9.9567, -10.5509, -16.5076,\n",
              "           -8.9573, -16.4170,  -5.5203, -10.0177,  -9.6641, -15.9953,  -8.6786,\n",
              "          -14.2977,  -2.9377, -15.4115, -15.4206, -15.7592, -15.1646, -15.8169,\n",
              "          -15.5817, -15.8458, -15.8947, -15.7586, -15.6662, -10.7847, -14.4726,\n",
              "          -14.6993,  -8.9694, -12.5941, -15.3049, -14.0032, -15.8081, -15.9366,\n",
              "          -16.1883, -16.1835, -15.4798, -15.5192, -14.0085, -15.8229, -15.3345,\n",
              "          -16.1317, -15.6514, -15.6215, -15.9976, -15.1477, -16.2800, -15.5339,\n",
              "          -15.5880, -15.7896, -15.9718, -15.8304, -16.2659, -15.5086, -16.1668,\n",
              "          -15.4124, -15.7799, -15.7035, -15.7393, -15.5695, -15.3740, -15.6188,\n",
              "          -16.0620, -15.9268, -15.6800]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.2542, -15.9714, -12.1545,  -8.6455, -16.7175, -16.8894, -10.2382,\n",
              "          -10.7105, -10.5267,  -9.7588, -11.8741, -14.1483, -12.6621, -16.9074,\n",
              "          -16.2157, -16.0956,  -9.5006, -15.9829, -13.3319, -16.4941, -11.6635,\n",
              "          -15.1970,  -6.0614, -15.4844,  -8.9167, -14.0248, -16.2928, -11.3836,\n",
              "          -16.1691,  -5.7200, -14.3162, -12.6719,  -3.0618, -11.7728,  -9.0170,\n",
              "          -13.4952, -11.1130,  -5.9523, -11.1231, -10.6895, -16.0687,  -8.6387,\n",
              "          -16.4481,  -9.4028,  -9.9526, -10.0133, -14.0172,  -9.9491,  -8.6628,\n",
              "           -4.2049, -16.9896, -10.9825, -15.8766, -17.5615,  -7.2847,  -9.7884,\n",
              "           -9.3919,  -4.0590, -11.2007, -16.2665, -16.5898,  -3.2658, -17.0732,\n",
              "           -4.8234,  -6.6252,  -5.4982,  -9.7215,  -9.8859, -10.8521, -17.2972,\n",
              "           -9.3262, -17.2768,  -5.3292, -10.2944,  -9.7359, -16.7770,  -8.6256,\n",
              "          -14.6404,  -2.5528, -16.2281, -16.3054, -16.6523, -16.0371, -16.7002,\n",
              "          -16.4317, -16.6601, -16.7000, -16.5579, -16.4728, -11.2958, -15.1338,\n",
              "          -15.2797,  -8.5591, -13.3222, -15.9425, -14.8401, -16.6217, -16.7982,\n",
              "          -16.9895, -17.0250, -16.3001, -16.3192, -14.6826, -16.6905, -16.1423,\n",
              "          -16.9634, -16.4733, -16.4854, -16.7847, -15.9220, -17.1335, -16.3931,\n",
              "          -16.3724, -16.6548, -16.8760, -16.6852, -17.0790, -16.3214, -17.0185,\n",
              "          -16.2641, -16.5984, -16.5261, -16.5688, -16.3654, -16.2269, -16.3929,\n",
              "          -16.8719, -16.6916, -16.6007]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.2388, -16.5667, -12.4803,  -8.7216, -17.3380, -17.5160, -10.3136,\n",
              "          -10.9745, -10.5141,  -9.8818, -12.1342, -14.6400, -13.2331, -17.5203,\n",
              "          -16.8331, -16.7480,  -9.6121, -16.4299, -13.9492, -17.1356, -11.9911,\n",
              "          -15.8033,  -6.2378, -16.1280,  -9.3357, -14.5868, -16.8502, -11.8455,\n",
              "          -16.7873,  -5.7384, -14.7709, -12.8078,  -3.2862, -12.3426,  -9.4867,\n",
              "          -14.1650, -11.2484,  -6.2977, -11.7600, -11.3231, -16.7691,  -8.5969,\n",
              "          -17.0344, -10.0686, -10.6290, -10.2257, -14.5021,  -9.8482,  -8.4913,\n",
              "           -4.4520, -17.6439, -10.9050, -16.5010, -18.1962,  -7.4748, -10.1055,\n",
              "           -9.6709,  -4.0249, -11.6842, -16.8805, -17.2383,  -3.3360, -17.7119,\n",
              "           -4.9768,  -6.6150,  -5.5332, -10.0124, -10.2394, -11.3703, -17.8572,\n",
              "           -9.7547, -17.9087,  -5.3959, -10.5349, -10.1041, -17.3685,  -8.9624,\n",
              "          -15.0580,  -2.4796, -16.8599, -16.9500, -17.2944, -16.6980, -17.3480,\n",
              "          -17.0721, -17.2744, -17.3708, -17.1450, -17.0892, -11.7208, -15.5992,\n",
              "          -15.8062,  -8.5796, -13.8666, -16.4797, -15.5634, -17.2201, -17.4023,\n",
              "          -17.5631, -17.6506, -16.8746, -16.9388, -15.1949, -17.3046, -16.7500,\n",
              "          -17.5538, -17.0738, -17.1292, -17.4148, -16.5137, -17.7338, -17.0430,\n",
              "          -16.9764, -17.2770, -17.5561, -17.3219, -17.6657, -16.9239, -17.6755,\n",
              "          -16.8904, -17.2425, -17.0724, -17.1996, -16.9533, -16.8448, -16.9780,\n",
              "          -17.4971, -17.3001, -17.2778]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.2179, -16.8409, -12.5855,  -8.7231, -17.6076, -17.7492, -10.4187,\n",
              "          -11.1415, -10.6797,  -9.9821, -12.5181, -14.8942, -13.5960, -17.7823,\n",
              "          -17.1195, -17.0216,  -9.7267, -16.6917, -14.2810, -17.4145, -12.2852,\n",
              "          -16.0848,  -6.3458, -16.4355,  -9.6186, -14.8537, -17.0760, -12.1014,\n",
              "          -17.0408,  -5.8597, -14.9892, -12.8743,  -3.5404, -12.6170,  -9.9071,\n",
              "          -14.4957, -11.2638,  -6.5285, -12.1235, -11.7143, -17.1514,  -8.5889,\n",
              "          -17.2751, -10.5557, -11.0899, -10.4378, -14.6820,  -9.9029,  -8.5335,\n",
              "           -4.7893, -17.9245, -10.8976, -16.8140, -18.4718,  -7.6419, -10.3284,\n",
              "           -9.8897,  -4.1575, -11.8713, -17.1318, -17.5314,  -3.4136, -17.9860,\n",
              "           -4.8036,  -6.5364,  -5.4915, -10.2112, -10.4437, -11.6143, -18.0643,\n",
              "           -9.8096, -18.1912,  -5.2919, -10.4500, -10.1606, -17.6159,  -9.0502,\n",
              "          -15.1595,  -2.4892, -17.1744, -17.2331, -17.5649, -16.9807, -17.6005,\n",
              "          -17.3516, -17.5434, -17.6623, -17.4117, -17.3755, -11.9766, -15.8075,\n",
              "          -16.0553,  -8.8606, -14.0925, -16.7610, -15.9950, -17.4765, -17.6604,\n",
              "          -17.8312, -17.9376, -17.1109, -17.1979, -15.4388, -17.5710, -17.0107,\n",
              "          -17.7985, -17.3402, -17.4282, -17.6946, -16.7718, -17.9711, -17.3256,\n",
              "          -17.2344, -17.5347, -17.8581, -17.5868, -17.9331, -17.1719, -17.9507,\n",
              "          -17.1719, -17.5215, -17.3027, -17.4811, -17.2019, -17.1224, -17.2377,\n",
              "          -17.7777, -17.5842, -17.5535]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.1960, -16.8448, -12.5443,  -8.6899, -17.5895, -17.7172, -10.4216,\n",
              "          -11.1836, -10.7555,  -9.9987, -12.6039, -14.9506, -13.6586, -17.7709,\n",
              "          -17.1408, -17.0214,  -9.7603, -16.7462, -14.3543, -17.4203, -12.4235,\n",
              "          -16.1029,  -6.3918, -16.4462,  -9.7581, -14.8416, -17.0455, -12.1141,\n",
              "          -16.9753,  -5.9815, -14.9814, -12.8533,  -3.5321, -12.5601, -10.2057,\n",
              "          -14.5959, -11.2747,  -6.5127, -12.0943, -11.9628, -17.2530,  -8.6018,\n",
              "          -17.2427, -10.7135, -11.2435, -10.6371, -14.7519,  -9.9956,  -8.6318,\n",
              "           -5.0256, -17.9106, -11.0306, -16.8250, -18.4544,  -7.6819, -10.3232,\n",
              "           -9.8577,  -4.2850, -11.8731, -17.1110, -17.5369,  -3.6188, -17.9749,\n",
              "           -4.7800,  -6.5551,  -5.5862, -10.3854, -10.5845, -11.6757, -18.0261,\n",
              "           -9.8445, -18.1734,  -5.3290, -10.4855, -10.2172, -17.6001,  -9.1721,\n",
              "          -15.2137,  -2.5824, -17.1909, -17.2430, -17.5636, -16.9737, -17.5808,\n",
              "          -17.3467, -17.5343, -17.6723, -17.4079, -17.3779, -12.0662, -15.8120,\n",
              "          -16.0779,  -9.1258, -14.2216, -16.8123, -16.1002, -17.4630, -17.6440,\n",
              "          -17.8343, -17.9366, -17.0875, -17.1770, -15.4767, -17.5607, -16.9862,\n",
              "          -17.7817, -17.3226, -17.4272, -17.6997, -16.7845, -17.9440, -17.3352,\n",
              "          -17.2234, -17.5224, -17.8754, -17.5798, -17.9402, -17.1468, -17.9377,\n",
              "          -17.1702, -17.5125, -17.2745, -17.4738, -17.1838, -17.1097, -17.2552,\n",
              "          -17.8001, -17.5716, -17.5389]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.1903, -16.7221, -12.4632,  -8.6286, -17.4503, -17.5673, -10.4268,\n",
              "          -11.2077, -10.8204, -10.0200, -12.6658, -14.9241, -13.5810, -17.6339,\n",
              "          -17.0341, -16.8758,  -9.7927, -16.7215, -14.2855, -17.2925, -12.4691,\n",
              "          -16.0197,  -6.4073, -16.3445,  -9.7697, -14.7154, -16.9035, -12.0515,\n",
              "          -16.8206,  -6.0842, -14.9056, -12.8210,  -3.4323, -12.3981, -10.3353,\n",
              "          -14.5200, -11.2375,  -6.4185, -11.9170, -12.0263, -17.1781,  -8.5997,\n",
              "          -17.0977, -10.7134, -11.2014, -10.7114, -14.6715, -10.0368,  -8.7787,\n",
              "           -5.1273, -17.7646, -11.1291, -16.6964, -18.3063,  -7.6824, -10.2824,\n",
              "           -9.7975,  -4.4087, -11.8051, -16.9673, -17.4039,  -3.7201, -17.8291,\n",
              "           -4.7311,  -6.5182,  -5.5956, -10.4053, -10.5648, -11.5629, -17.8815,\n",
              "           -9.7608, -18.0248,  -5.3039, -10.4496, -10.1405, -17.4567,  -9.1321,\n",
              "          -15.1598,  -2.6285, -17.0713, -17.1161, -17.4291, -16.8318, -17.4274,\n",
              "          -17.2138, -17.4000, -17.5298, -17.2736, -17.2576, -12.0415, -15.7294,\n",
              "          -15.9795,  -9.3114, -14.2104, -16.7387, -16.0289, -17.3303, -17.5124,\n",
              "          -17.7188, -17.8070, -16.9558, -17.0247, -15.4021, -17.4258, -16.8428,\n",
              "          -17.6403, -17.1791, -17.2993, -17.5731, -16.6691, -17.7956, -17.2072,\n",
              "          -17.0880, -17.3814, -17.7534, -17.4441, -17.8222, -17.0024, -17.7858,\n",
              "          -17.0334, -17.3743, -17.1415, -17.3280, -17.0448, -16.9724, -17.1456,\n",
              "          -17.6830, -17.4357, -17.3921]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.1912, -16.5805, -12.3924,  -8.5627, -17.2971, -17.4172, -10.3828,\n",
              "          -11.1989, -10.8062,  -9.9949, -12.6191, -14.8662, -13.4700, -17.4858,\n",
              "          -16.9054, -16.7188,  -9.7633, -16.6466, -14.1675, -17.1468, -12.4218,\n",
              "          -15.9102,  -6.3964, -16.2540,  -9.7104, -14.5750, -16.7553, -11.9868,\n",
              "          -16.6990,  -6.1144, -14.8238, -12.7649,  -3.3040, -12.2600, -10.3305,\n",
              "          -14.4208, -11.1954,  -6.3329, -11.7505, -12.0055, -17.0659,  -8.5681,\n",
              "          -16.9481, -10.6463, -11.1020, -10.6970, -14.5886, -10.0171,  -8.8388,\n",
              "           -5.1407, -17.6039, -11.1770, -16.5406, -18.1456,  -7.6412, -10.2345,\n",
              "           -9.7238,  -4.4582, -11.7460, -16.8147, -17.2475,  -3.7821, -17.6710,\n",
              "           -4.7738,  -6.4964,  -5.5860, -10.3961, -10.5262, -11.4471, -17.7351,\n",
              "           -9.7068, -17.8646,  -5.3110, -10.4445, -10.0891, -17.3011,  -9.1033,\n",
              "          -15.1288,  -2.6474, -16.9204, -16.9694, -17.2749, -16.6765, -17.2707,\n",
              "          -17.0649, -17.2517, -17.3698, -17.1208, -17.1162, -11.9799, -15.6361,\n",
              "          -15.8601,  -9.3532, -14.1755, -16.6407, -15.9045, -17.1863, -17.3675,\n",
              "          -17.5776, -17.6602, -16.8178, -16.8656, -15.2925, -17.2773, -16.6889,\n",
              "          -17.4886, -17.0179, -17.1509, -17.4276, -16.5351, -17.6446, -17.0615,\n",
              "          -16.9394, -17.2303, -17.6046, -17.2995, -17.6820, -16.8497, -17.6270,\n",
              "          -16.8792, -17.2198, -16.9979, -17.1663, -16.8927, -16.8144, -17.0163,\n",
              "          -17.5418, -17.2846, -17.2343]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.1962, -16.4885, -12.3582,  -8.5088, -17.1995, -17.3210, -10.3447,\n",
              "          -11.1912, -10.7766,  -9.9659, -12.5917, -14.8223, -13.4004, -17.3903,\n",
              "          -16.8164, -16.6119,  -9.7232, -16.5868, -14.0707, -17.0480, -12.3554,\n",
              "          -15.8378,  -6.3769, -16.2196,  -9.6299, -14.4870, -16.6599, -11.9644,\n",
              "          -16.6577,  -6.1011, -14.7814, -12.7215,  -3.2277, -12.2077, -10.2638,\n",
              "          -14.3408, -11.1460,  -6.3054, -11.6798, -11.9470, -16.9866,  -8.5175,\n",
              "          -16.8573, -10.6006, -11.0196, -10.6214, -14.5079,  -9.9557,  -8.8466,\n",
              "           -5.1075, -17.5004, -11.1439, -16.4364, -18.0413,  -7.6057, -10.2317,\n",
              "           -9.7155,  -4.4697, -11.7213, -16.7167, -17.1434,  -3.7730, -17.5652,\n",
              "           -4.7920,  -6.4609,  -5.5273, -10.3542, -10.4679, -11.3683, -17.6410,\n",
              "           -9.6451, -17.7631,  -5.2880, -10.4034, -10.0220, -17.1948,  -9.0434,\n",
              "          -15.0937,  -2.6405, -16.8175, -16.8669, -17.1691, -16.5778, -17.1671,\n",
              "          -16.9666, -17.1557, -17.2579, -17.0171, -17.0241, -11.9235, -15.5765,\n",
              "          -15.7796,  -9.3167, -14.1310, -16.5738, -15.8162, -17.0931, -17.2739,\n",
              "          -17.4827, -17.5659, -16.7321, -16.7636, -15.2066, -17.1823, -16.5927,\n",
              "          -17.3897, -16.9106, -17.0559, -17.3308, -16.4395, -17.5477, -16.9631,\n",
              "          -16.8401, -17.1310, -17.4984, -17.2079, -17.5863, -16.7533, -17.5272,\n",
              "          -16.7770, -17.1180, -16.9069, -17.0592, -16.7926, -16.7111, -16.9235,\n",
              "          -17.4407, -17.1897, -17.1322]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.2000, -16.4595, -12.3528,  -8.4720, -17.1668, -17.2905, -10.3136,\n",
              "          -11.1876, -10.7317,  -9.9342, -12.5651, -14.8093, -13.3846, -17.3594,\n",
              "          -16.7849, -16.5747,  -9.6796, -16.5561, -14.0225, -17.0127, -12.3014,\n",
              "          -15.8139,  -6.3627, -16.2402,  -9.5723, -14.4602, -16.6275, -11.9741,\n",
              "          -16.6779,  -6.0682, -14.7777, -12.6941,  -3.1949, -12.2214, -10.2060,\n",
              "          -14.3175, -11.1160,  -6.3168, -11.6863, -11.9139, -16.9692,  -8.4655,\n",
              "          -16.8323, -10.5888, -10.9843, -10.5539, -14.4778,  -9.8939,  -8.8139,\n",
              "           -5.0751, -17.4669, -11.0870, -16.3978, -18.0051,  -7.5798, -10.2485,\n",
              "           -9.7422,  -4.4512, -11.7297, -16.6841, -17.1069,  -3.7559, -17.5266,\n",
              "           -4.8187,  -6.4408,  -5.4737, -10.3366, -10.4428, -11.3546, -17.6098,\n",
              "           -9.6217, -17.7297,  -5.2758, -10.3771,  -9.9909, -17.1538,  -9.0175,\n",
              "          -15.0935,  -2.6301, -16.7773, -16.8276, -17.1305, -16.5474, -17.1323,\n",
              "          -16.9332, -17.1237, -17.2179, -16.9785, -16.9933, -11.8995, -15.5579,\n",
              "          -15.7534,  -9.2500, -14.1232, -16.5556, -15.7869, -17.0628, -17.2422,\n",
              "          -17.4473, -17.5372, -16.7060, -16.7304, -15.1665, -17.1527, -16.5623,\n",
              "          -17.3582, -16.8699, -17.0252, -17.2975, -16.4034, -17.5174, -16.9296,\n",
              "          -16.8042, -17.0977, -17.4549, -17.1828, -17.5514, -16.7225, -17.4984,\n",
              "          -16.7416, -17.0824, -16.8766, -17.0223, -16.7563, -16.6728, -16.8872,\n",
              "          -17.4013, -17.1587, -17.0988]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.2024, -16.4780, -12.3667,  -8.4532, -17.1831, -17.3056, -10.3033,\n",
              "          -11.1953, -10.6996,  -9.9166, -12.5696, -14.8229, -13.4101, -17.3754,\n",
              "          -16.7983, -16.5868,  -9.6528, -16.5578, -14.0190, -17.0252, -12.2779,\n",
              "          -15.8289,  -6.3554, -16.2886,  -9.5447, -14.4744, -16.6406, -11.9998,\n",
              "          -16.7265,  -6.0386, -14.7993, -12.6870,  -3.1944, -12.2678, -10.1805,\n",
              "          -14.3305, -11.1010,  -6.3456, -11.7340, -11.9083, -16.9958,  -8.4245,\n",
              "          -16.8533, -10.6078, -10.9894, -10.5140, -14.4794,  -9.8502,  -8.7775,\n",
              "           -5.0572, -17.4842, -11.0302, -16.4107, -18.0197,  -7.5715, -10.2763,\n",
              "           -9.7919,  -4.4281, -11.7536, -16.6983, -17.1210,  -3.7355, -17.5377,\n",
              "           -4.8249,  -6.4238,  -5.4258, -10.3337, -10.4359, -11.3785, -17.6234,\n",
              "           -9.6131, -17.7454,  -5.2568, -10.3515,  -9.9727, -17.1609,  -9.0030,\n",
              "          -15.1060,  -2.6204, -16.7881, -16.8364, -17.1426, -16.5664, -17.1454,\n",
              "          -16.9485, -17.1388, -17.2300, -16.9893, -17.0099, -11.9018, -15.5697,\n",
              "          -15.7675,  -9.1977, -14.1394, -16.5738, -15.8062, -17.0791, -17.2570,\n",
              "          -17.4597, -17.5565, -16.7227, -16.7459, -15.1663, -17.1707, -16.5798,\n",
              "          -17.3751, -16.8803, -17.0432, -17.3122, -16.4124, -17.5330, -16.9444,\n",
              "          -16.8161, -17.1125, -17.4618, -17.2043, -17.5631, -16.7385, -17.5191,\n",
              "          -16.7558, -17.0963, -16.8918, -17.0364, -16.7678, -16.6848, -16.8942,\n",
              "          -17.4094, -17.1753, -17.1151]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.2026, -16.5186, -12.3866,  -8.4460, -17.2217, -17.3417, -10.3030,\n",
              "          -11.2074, -10.6773,  -9.9079, -12.5863, -14.8504, -13.4551, -17.4129,\n",
              "          -16.8343, -16.6237,  -9.6377, -16.5763, -14.0416, -17.0614, -12.2766,\n",
              "          -15.8621,  -6.3532, -16.3428,  -9.5430, -14.5061, -16.6748, -12.0258,\n",
              "          -16.7777,  -6.0192, -14.8290, -12.6908,  -3.2058, -12.3185, -10.1886,\n",
              "          -14.3658, -11.0987,  -6.3734, -11.7894, -11.9292, -17.0456,  -8.3963,\n",
              "          -16.8940, -10.6417, -11.0184, -10.5063, -14.5055,  -9.8287,  -8.7462,\n",
              "           -5.0595, -17.5247, -10.9941, -16.4478, -18.0580,  -7.5733, -10.3001,\n",
              "           -9.8399,  -4.4078, -11.7811, -16.7338, -17.1592,  -3.7298, -17.5729,\n",
              "           -4.8270,  -6.4144,  -5.3963, -10.3486, -10.4483, -11.4231, -17.6579,\n",
              "           -9.6212, -17.7828,  -5.2438, -10.3388,  -9.9722, -17.1917,  -9.0081,\n",
              "          -15.1302,  -2.6194, -16.8240, -16.8697, -17.1796, -16.6077, -17.1814,\n",
              "          -16.9870, -17.1752, -17.2689, -17.0244, -17.0487, -11.9201, -15.5956,\n",
              "          -15.8012,  -9.1686, -14.1744, -16.6105, -15.8504, -17.1173, -17.2933,\n",
              "          -17.4952, -17.5979, -16.7583, -16.7836, -15.1885, -17.2106, -16.6183,\n",
              "          -17.4145, -16.9149, -17.0835, -17.3499, -16.4449, -17.5696, -16.9825,\n",
              "          -16.8512, -17.1503, -17.4952, -17.2470, -17.5976, -16.7751, -17.5622,\n",
              "          -16.7935, -17.1336, -16.9272, -17.0749, -16.8017, -16.7203, -16.9242,\n",
              "          -17.4425, -17.2129, -17.1547]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.2015, -16.5612, -12.4048,  -8.4448, -17.2627, -17.3788, -10.3088,\n",
              "          -11.2207, -10.6662,  -9.9068, -12.6126, -14.8797, -13.5022, -17.4521,\n",
              "          -16.8737, -16.6631,  -9.6326, -16.5997, -14.0717, -17.1007, -12.2877,\n",
              "          -15.8976,  -6.3534, -16.3877,  -9.5541, -14.5373, -16.7107, -12.0451,\n",
              "          -16.8174,  -6.0118, -14.8565, -12.6995,  -3.2194, -12.3586, -10.2162,\n",
              "          -14.4029, -11.1007,  -6.3937, -11.8349, -11.9608, -17.0971,  -8.3786,\n",
              "          -16.9348, -10.6782, -11.0527, -10.5178, -14.5358,  -9.8230,  -8.7280,\n",
              "           -5.0742, -17.5668, -10.9755, -16.4882, -18.0989,  -7.5802, -10.3177,\n",
              "           -9.8807,  -4.3972, -11.8032, -16.7709, -17.2005,  -3.7334, -17.6111,\n",
              "           -4.8212,  -6.4074,  -5.3793, -10.3685, -10.4657, -11.4677, -17.6941,\n",
              "           -9.6315, -17.8215,  -5.2314, -10.3305,  -9.9751, -17.2255,  -9.0167,\n",
              "          -15.1524,  -2.6258, -16.8644, -16.9069, -17.2200, -16.6505, -17.2191,\n",
              "          -17.0282, -17.2131, -17.3115, -17.0631, -17.0902, -11.9423, -15.6224,\n",
              "          -15.8371,  -9.1621, -14.2116, -16.6492, -15.8986, -17.1574, -17.3317,\n",
              "          -17.5348, -17.6408, -16.7946, -16.8225, -15.2169, -17.2520, -16.6579,\n",
              "          -17.4553, -16.9529, -17.1260, -17.3903, -16.4814, -17.6069, -17.0231,\n",
              "          -16.8894, -17.1903, -17.5339, -17.2905, -17.6354, -16.8128, -17.6063,\n",
              "          -16.8338, -17.1735, -16.9641, -17.1159, -16.8383, -16.7593, -16.9582,\n",
              "          -17.4799, -17.2523, -17.1962]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.1997, -16.5956, -12.4174,  -8.4450, -17.2953, -17.4074, -10.3147,\n",
              "          -11.2315, -10.6599,  -9.9082, -12.6373, -14.9041, -13.5414, -17.4833,\n",
              "          -16.9062, -16.6944,  -9.6314, -16.6197, -14.0983, -17.1327, -12.3014,\n",
              "          -15.9261,  -6.3543, -16.4193,  -9.5683, -14.5597, -16.7389, -12.0560,\n",
              "          -16.8423,  -6.0126, -14.8770, -12.7078,  -3.2289, -12.3841, -10.2500,\n",
              "          -14.4332, -11.1037,  -6.4056, -11.8645, -11.9936, -17.1399,  -8.3674,\n",
              "          -16.9662, -10.7087, -11.0815, -10.5382, -14.5630,  -9.8259,  -8.7199,\n",
              "           -5.0937, -17.5999, -10.9698, -16.5204, -18.1314,  -7.5865, -10.3278,\n",
              "           -9.9107,  -4.3944, -11.8174, -16.7997, -17.2336,  -3.7444, -17.6417,\n",
              "           -4.8153,  -6.4033,  -5.3726, -10.3896, -10.4839, -11.5047, -17.7227,\n",
              "           -9.6421, -17.8514,  -5.2230, -10.3270,  -9.9797, -17.2521,  -9.0268,\n",
              "          -15.1709,  -2.6377, -16.8976, -16.9371, -17.2527, -16.6841, -17.2486,\n",
              "          -17.0612, -17.2425, -17.3463, -17.0946, -17.1237, -11.9618, -15.6434,\n",
              "          -15.8663,  -9.1684, -14.2447, -16.6814, -15.9387, -17.1891, -17.3622,\n",
              "          -17.5674, -17.6751, -16.8227, -16.8527, -15.2417, -17.2848, -16.6885,\n",
              "          -17.4874, -16.9830, -17.1599, -17.4230, -16.5118, -17.6356, -17.0559,\n",
              "          -16.9200, -17.2222, -17.5662, -17.3253, -17.6662, -16.8418, -17.6412,\n",
              "          -16.8659, -17.2052, -16.9926, -17.1485, -16.8675, -16.7905, -16.9865,\n",
              "          -17.5107, -17.2834, -17.2291]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.1979, -16.6195, -12.4250,  -8.4451, -17.3174, -17.4261, -10.3191,\n",
              "          -11.2396, -10.6557,  -9.9101, -12.6584, -14.9217, -13.5702, -17.5043,\n",
              "          -16.9293, -16.7150,  -9.6314, -16.6338, -14.1171, -17.1546, -12.3127,\n",
              "          -15.9458,  -6.3546, -16.4393,  -9.5792, -14.5721, -16.7576, -12.0603,\n",
              "          -16.8554,  -6.0175, -14.8906, -12.7140,  -3.2340, -12.3978, -10.2800,\n",
              "          -14.4530, -11.1050,  -6.4116, -11.8806, -12.0202, -17.1703,  -8.3594,\n",
              "          -16.9871, -10.7306, -11.1008, -10.5584, -14.5824,  -9.8312,  -8.7185,\n",
              "           -5.1113, -17.6219, -10.9692, -16.5422, -18.1532,  -7.5904, -10.3331,\n",
              "           -9.9327,  -4.3966, -11.8246, -16.8185, -17.2563,  -3.7564, -17.6622,\n",
              "           -4.8092,  -6.3997,  -5.3702, -10.4068, -10.4976, -11.5313, -17.7419,\n",
              "           -9.6491, -17.8707,  -5.2162, -10.3243,  -9.9818, -17.2691,  -9.0329,\n",
              "          -15.1833,  -2.6511, -16.9208, -16.9575, -17.2748, -16.7066, -17.2676,\n",
              "          -17.0838, -17.2616, -17.3703, -17.1162, -17.1472, -11.9758, -15.6573,\n",
              "          -15.8863,  -9.1790, -14.2694, -16.7047, -15.9674, -17.2107, -17.3827,\n",
              "          -17.5905, -17.6987, -16.8411, -16.8723, -15.2594, -17.3069, -16.7087,\n",
              "          -17.5088, -17.0030, -17.1831, -17.4455, -16.5331, -17.6541, -17.0784,\n",
              "          -16.9408, -17.2439, -17.5887, -17.3494, -17.6874, -16.8608, -17.6648,\n",
              "          -16.8877, -17.2265, -17.0112, -17.1704, -16.8870, -16.8118, -17.0060,\n",
              "          -17.5320, -17.3043, -17.2513]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.1963, -16.6355, -12.4295,  -8.4444, -17.3317, -17.4375, -10.3211,\n",
              "          -11.2449, -10.6507,  -9.9109, -12.6740, -14.9335, -13.5907, -17.5180,\n",
              "          -16.9448, -16.7276,  -9.6305, -16.6424, -14.1289, -17.1689, -12.3195,\n",
              "          -15.9584,  -6.3541, -16.4522,  -9.5852, -14.5775, -16.7694, -12.0610,\n",
              "          -16.8621,  -6.0225, -14.8996, -12.7176,  -3.2360, -12.4049, -10.3028,\n",
              "          -14.4648, -11.1044,  -6.4148, -11.8892, -12.0394, -17.1908,  -8.3526,\n",
              "          -17.0004, -10.7447, -11.1122, -10.5747, -14.5957,  -9.8357,  -8.7188,\n",
              "           -5.1245, -17.6358, -10.9693, -16.5559, -18.1672,  -7.5917, -10.3355,\n",
              "           -9.9495,  -4.3999, -11.8276, -16.8301, -17.2709,  -3.7669, -17.6751,\n",
              "           -4.8051,  -6.3967,  -5.3693, -10.4200, -10.5069, -11.5502, -17.7542,\n",
              "           -9.6537, -17.8825,  -5.2110, -10.3221,  -9.9821, -17.2791,  -9.0359,\n",
              "          -15.1919,  -2.6640, -16.9360, -16.9703, -17.2889, -16.7209, -17.2790,\n",
              "          -17.0986, -17.2732, -17.3860, -17.1302, -17.1629, -11.9849, -15.6659,\n",
              "          -15.8994,  -9.1878, -14.2871, -16.7211, -15.9867, -17.2247, -17.3958,\n",
              "          -17.6059, -17.7143, -16.8525, -16.8844, -15.2710, -17.3210, -16.7214,\n",
              "          -17.5225, -17.0154, -17.1982, -17.4604, -16.5472, -17.6653, -17.0932,\n",
              "          -16.9541, -17.2580, -17.6032, -17.3658, -17.7013, -16.8726, -17.6803,\n",
              "          -16.9015, -17.2400, -17.0227, -17.1843, -16.8994, -16.8253, -17.0185,\n",
              "          -17.5458, -17.3177, -17.2656]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.1951, -16.6475, -12.4329,  -8.4434, -17.3423, -17.4458, -10.3216,\n",
              "          -11.2485, -10.6446,  -9.9107, -12.6859, -14.9418, -13.6064, -17.5280,\n",
              "          -16.9563, -16.7362,  -9.6284, -16.6477, -14.1365, -17.1792, -12.3227,\n",
              "          -15.9672,  -6.3527, -16.4623,  -9.5873, -14.5799, -16.7780, -12.0605,\n",
              "          -16.8671,  -6.0258, -14.9065, -12.7196,  -3.2370, -12.4101, -10.3185,\n",
              "          -14.4719, -11.1025,  -6.4178, -11.8955, -12.0525, -17.2057,  -8.3457,\n",
              "          -17.0104, -10.7540, -11.1189, -10.5864, -14.6052,  -9.8381,  -8.7184,\n",
              "           -5.1332, -17.6458, -10.9675, -16.5657, -18.1774,  -7.5913, -10.3374,\n",
              "           -9.9645,  -4.4022, -11.8290, -16.8382, -17.2815,  -3.7743, -17.6843,\n",
              "           -4.8019,  -6.3937,  -5.3679, -10.4297, -10.5127, -11.5650, -17.7633,\n",
              "           -9.6564, -17.8908,  -5.2063, -10.3193,  -9.9810, -17.2857,  -9.0364,\n",
              "          -15.1980,  -2.6753, -16.9470, -16.9791, -17.2989, -16.7313, -17.2870,\n",
              "          -17.1095, -17.2811, -17.3975, -17.1404, -17.1748, -11.9908, -15.6720,\n",
              "          -15.9088,  -9.1924, -14.2998, -16.7335, -16.0006, -17.2350, -17.4052,\n",
              "          -17.6174, -17.7259, -16.8607, -16.8931, -15.2790, -17.3313, -16.7307,\n",
              "          -17.5324, -17.0241, -17.2094, -17.4715, -16.5576, -17.6733, -17.1042,\n",
              "          -16.9637, -17.2683, -17.6135, -17.3783, -17.7116, -16.8812, -17.6920,\n",
              "          -16.9114, -17.2496, -17.0308, -17.1943, -16.9084, -16.8351, -17.0273,\n",
              "          -17.5555, -17.3275, -17.2762]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.1941, -16.6587, -12.4363,  -8.4426, -17.3523, -17.4536, -10.3213,\n",
              "          -11.2511, -10.6374,  -9.9097, -12.6954, -14.9487, -13.6204, -17.5374,\n",
              "          -16.9668, -16.7443,  -9.6255, -16.6519, -14.1427, -17.1887, -12.3238,\n",
              "          -15.9749,  -6.3508, -16.4725,  -9.5872, -14.5822, -16.7862, -12.0604,\n",
              "          -16.8730,  -6.0271, -14.9132, -12.7210,  -3.2385, -12.4163, -10.3298,\n",
              "          -14.4779, -11.1001,  -6.4216, -11.9029, -12.0622, -17.2189,  -8.3388,\n",
              "          -17.0201, -10.7612, -11.1241, -10.5950, -14.6138,  -9.8390,  -8.7160,\n",
              "           -5.1388, -17.6553, -10.9638, -16.5747, -18.1870,  -7.5904, -10.3396,\n",
              "           -9.9791,  -4.4027, -11.8307, -16.8460, -17.2914,  -3.7793, -17.6930,\n",
              "           -4.7997,  -6.3909,  -5.3658, -10.4373, -10.5168, -11.5789, -17.7721,\n",
              "           -9.6588, -17.8988,  -5.2020, -10.3163,  -9.9797, -17.2921,  -9.0360,\n",
              "          -15.2035,  -2.6851, -16.9571, -16.9871, -17.3081, -16.7410, -17.2946,\n",
              "          -17.1197, -17.2886, -17.4082, -17.1499, -17.1859, -11.9954, -15.6777,\n",
              "          -15.9172,  -9.1933, -14.3105, -16.7447, -16.0127, -17.2448, -17.4139,\n",
              "          -17.6280, -17.7367, -16.8685, -16.9016, -15.2858, -17.3409, -16.7396,\n",
              "          -17.5418, -17.0323, -17.2198, -17.4819, -16.5671, -17.6810, -17.1143,\n",
              "          -16.9726, -17.2779, -17.6228, -17.3902, -17.7210, -16.8894, -17.7031,\n",
              "          -16.9207, -17.2586, -17.0385, -17.2036, -16.9171, -16.8442, -17.0353,\n",
              "          -17.5644, -17.3368, -17.2862]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.1932, -16.6707, -12.4402,  -8.4422, -17.3631, -17.4626, -10.3211,\n",
              "          -11.2535, -10.6299,  -9.9085, -12.7039, -14.9556, -13.6344, -17.5477,\n",
              "          -16.9778, -16.7533,  -9.6225, -16.6562, -14.1490, -17.1991, -12.3245,\n",
              "          -15.9829,  -6.3486, -16.4836,  -9.5867, -14.5859, -16.7954, -12.0611,\n",
              "          -16.8805,  -6.0269, -14.9204, -12.7225,  -3.2410, -12.4240, -10.3392,\n",
              "          -14.4844, -11.0978,  -6.4262, -11.9123, -12.0706, -17.2324,  -8.3319,\n",
              "          -17.0308, -10.7679, -11.1296, -10.6023, -14.6227,  -9.8391,  -8.7122,\n",
              "           -5.1431, -17.6659, -10.9591, -16.5847, -18.1976,  -7.5898, -10.3423,\n",
              "           -9.9939,  -4.4016, -11.8334, -16.8549, -17.3022,  -3.7828, -17.7026,\n",
              "           -4.7976,  -6.3884,  -5.3634, -10.4440, -10.5204, -11.5931, -17.7818,\n",
              "           -9.6614, -17.9079,  -5.1979, -10.3134,  -9.9787, -17.2997,  -9.0356,\n",
              "          -15.2090,  -2.6938, -16.9679, -16.9960, -17.3183, -16.7517, -17.3034,\n",
              "          -17.1309, -17.2971, -17.4198, -17.1604, -17.1976, -12.0000, -15.6840,\n",
              "          -15.9263,  -9.1918, -14.3207, -16.7562, -16.0250, -17.2555, -17.4236,\n",
              "          -17.6392, -17.7483, -16.8773, -16.9114, -15.2929, -17.3514, -16.7496,\n",
              "          -17.5522, -17.0416, -17.2310, -17.4931, -16.5774, -17.6898, -17.1253,\n",
              "          -16.9825, -17.2885, -17.6329, -17.4029, -17.7313, -16.8989, -17.7153,\n",
              "          -16.9309, -17.2686, -17.0472, -17.2140, -16.9267, -16.8543, -17.0440,\n",
              "          -17.5740, -17.3470, -17.2973]], grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.1923, -16.6836, -12.4446,  -8.4423, -17.3750, -17.4728, -10.3212,\n",
              "          -11.2559, -10.6227,  -9.9075, -12.7121, -14.9627, -13.6489, -17.5591,\n",
              "          -16.9899, -16.7637,  -9.6199, -16.6612, -14.1561, -17.2105, -12.3255,\n",
              "          -15.9917,  -6.3465, -16.4955,  -9.5866, -14.5910, -16.8058, -12.0623,\n",
              "          -16.8892,  -6.0261, -14.9281, -12.7244,  -3.2443, -12.4329, -10.3484,\n",
              "          -14.4919, -11.0961,  -6.4311, -11.9230, -12.0792, -17.2469,  -8.3255,\n",
              "          -17.0426, -10.7749, -11.1362, -10.6095, -14.6326,  -9.8394,  -8.7077,\n",
              "           -5.1470, -17.6778, -10.9545, -16.5959, -18.2095,  -7.5898, -10.3453,\n",
              "          -10.0088,  -4.3994, -11.8369, -16.8651, -17.3142,  -3.7857, -17.7135,\n",
              "           -4.7956,  -6.3863,  -5.3613, -10.4505, -10.5242, -11.6081, -17.7926,\n",
              "           -9.6645, -17.9182,  -5.1941, -10.3108,  -9.9784, -17.3086,  -9.0358,\n",
              "          -15.2148,  -2.7019, -16.9799, -17.0062, -17.3298, -16.7636, -17.3135,\n",
              "          -17.1433, -17.3069, -17.4327, -17.1720, -17.2104, -12.0050, -15.6911,\n",
              "          -15.9362,  -9.1897, -14.3313, -16.7684, -16.0383, -17.2674, -17.4343,\n",
              "          -17.6514, -17.7611, -16.8871, -16.9225, -15.3008, -17.3630, -16.7608,\n",
              "          -17.5638, -17.0523, -17.2434, -17.5053, -16.5886, -17.6998, -17.1374,\n",
              "          -16.9934, -17.3003, -17.6441, -17.4166, -17.7427, -16.9095, -17.7286,\n",
              "          -16.9422, -17.2799, -17.0570, -17.2256, -16.9377, -16.8656, -17.0538,\n",
              "          -17.5847, -17.3585, -17.3097]], grad_fn=<ViewBackward>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukoNAs8wP-GH",
        "colab_type": "text"
      },
      "source": [
        "## Exercises\n",
        "\n",
        "1. Train longer and check accuracy - play with different hyperparameters\n",
        "2. Visualise attention - which part of the encoder output are we attending to\n",
        "3. Improve performance with batching - use the packing idea from earlier\n",
        "4. Try other attention mechanisms\n"
      ]
    }
  ]
}